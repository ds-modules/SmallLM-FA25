{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "974a3699-87cd-4c24-b653-bab6230adda6",
   "metadata": {},
   "source": [
    "# Exploring the Anthropic API: Tokens, Costs, and Usage\n",
    "\n",
    "This notebook demonstrates how to interact with the **Anthropic API** from Python in a reproducible classroom or research environment.  \n",
    "The focus is on understanding how **tokenization**, **model usage**, and **costs per token** work in practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6aa16e-95df-4ab1-84e4-c56eb8a517f9",
   "metadata": {},
   "source": [
    "## What the Notebook Does\n",
    "\n",
    "1. **Connects to the Anthropic API** using the shared API key.  \n",
    "2. **Sends example prompts** to Claude models (e.g., `claude-sonnet-4` or `claude-haiku-4`) to illustrate response quality and cost trade-offs.  \n",
    "3. **Explores tokenization** — how text is converted into tokens and how token counts vary by model.  \n",
    "4. **Calculates API usage costs**, showing how prompt length and model choice affect pricing.  \n",
    "5. **Visualizes results**, helping students understand the relationship between:\n",
    "   - Input text length (number of tokens)\n",
    "   - Model type and context window\n",
    "   - Cost per request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1784fb-3795-42e4-bc78-622fcfbd20c7",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "- Understand what a **token** is and how it differs from characters or words.  \n",
    "- Learn to estimate and monitor **API usage costs**.  \n",
    "- Gain experience working with **environment variables** and best practices for secret management.  \n",
    "- Build intuition for **trade-offs between model size, latency, and price** in practical applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3118db0d-0bc8-4419-8dbd-8963a803dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328f7c2-0df4-4d22-8deb-a03e0ce5567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "except:\n",
    "    !pip install python-dotenv\n",
    "    from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a731ec-e558-421a-8ae5-57b81cee984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import anthropic\n",
    "except ImportError:\n",
    "    !pip install anthropic\n",
    "    import anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f3d98-60b7-4b96-b43d-d3f1f74492d7",
   "metadata": {},
   "source": [
    "## API Key Setup\n",
    "\n",
    "To keep credentials secure, the API key is **not stored directly in this notebook**.  \n",
    "\n",
    "*The API key is linked to my credit card, so if it gets out the charges could add up. If I put the API key on Github it will automatically be flagged.* \n",
    "\n",
    "Instead, it is stored in a `.env` file inside a shared directory (`../shared/.env`) with a line like:\n",
    "\n",
    "```\n",
    "ANTHROPIC_API_KEY=your_api_key_here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1299a86-ad63-4326-b70d-ac04d6de2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('../shared_readwrite/.env')\n",
    "\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "print(\"API Key loaded:\", \"✅\" if anthropic_api_key else \"❌ not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2821fcea-66bd-4849-8102-a20bf76e3b08",
   "metadata": {},
   "source": [
    "(option to manually load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613fee75-6964-45a3-a75b-d9c154fad9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is just if you want to manually load a different API Key\n",
    "#anthropic_api_key = \"sk-ant-XXXXYYYYYYYYYYYYYYYYYYYYYYYYYY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafc48c7-595f-41e3-b565-49cb873ec662",
   "metadata": {},
   "source": [
    "### Notes for Instructors\n",
    "\n",
    "- The shared `.env` file allows multiple users on the same DataHub instance or Jupyter environment to access a single institutional API key without embedding secrets in their notebooks.  \n",
    "- Students should **never print the API key** or share the `.env` file contents publicly.  \n",
    "- The key can be rotated by updating the shared `.env` file; all dependent notebooks will continue to function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9f10c0-5575-487a-9920-5f27d8347837",
   "metadata": {},
   "source": [
    "## The Anthropic Python Package\n",
    "\n",
    "The **Anthropic Python package** provides a simple interface for interacting with Claude models directly from Python code. It supports both synchronous and asynchronous API calls, making it easy to send prompts, generate completions, and analyze responses. The package handles authentication via an environment variable (`ANTHROPIC_API_KEY`) and returns structured results that can be easily integrated into data workflows, Jupyter notebooks, or applications for natural language processing, code generation, or AI-assisted analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5e013c-f6ea-448e-9611-f71587e0584d",
   "metadata": {},
   "source": [
    "### Initializing the Anthropic Client\n",
    "\n",
    "Once the API key is loaded from the environment, we create a client object that serves as our connection to the Anthropic API.  \n",
    "This client will handle authentication and allow us to make requests to different Claude models.  \n",
    "\n",
    "We'll initialize it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5434c-dcb7-4274-99b9-8ef0a42c557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = anthropic.Anthropic(api_key=anthropic_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c3afe-cf5b-457a-a200-207ba9bbeae6",
   "metadata": {},
   "source": [
    "### Available Claude Models\n",
    "\n",
    "Anthropic offers several Claude models with different capabilities and price points:\n",
    "\n",
    "- **claude-opus-4** - Most capable model for complex tasks\n",
    "- **claude-sonnet-4** - Balanced performance and speed\n",
    "- **claude-haiku-4** - Fastest and most affordable\n",
    "\n",
    "Note: Unlike OpenAI, Anthropic doesn't provide a models.list() endpoint, so you need to refer to the documentation for available models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327b5fd7-b62b-4d6e-bed7-d028f77c5903",
   "metadata": {},
   "source": [
    "## Basic Message Example\n",
    "\n",
    "To demonstrate the simplest API call, we can send a message request to Claude.  \n",
    "Here, we use `client.messages.create()` to send a conversation.  \n",
    "The model responds based on the system prompt and user messages provided.\n",
    "\n",
    "In this example, the system message defines the context (\"You are a UC Berkeley Economics student\"), and the user asks a question (\"Explain who pays the burden of tariffs\").  \n",
    "The model returns a text completion that we can extract and display from the `response` object.\n",
    "\n",
    "This basic pattern—system prompt, user message, and model reply—is the foundation of all interactions with Claude models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102fb7f6-fc48-462c-b9b6-6f648bd1dc67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Send a message to Claude\n",
    "response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    system=\"You are a UC Berkeley Economics Student\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain who pays the burden of tariffs\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display response\n",
    "print(response.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e8c57-e154-4c86-9f6a-9b1cbd75b394",
   "metadata": {},
   "source": [
    "### Anthropic Token Pricing (as of October 2025)\n",
    "[Anthropic API Pricing] (https://claude.com/pricing#api)\n",
    "\n",
    "| Model              | Input Tokens (per 1M) | Output Tokens (per 1M) | Context Window     |\n",
    "|-------------------|-----------------------|-------------------------|--------------------|\n",
    "| **Claude Opus 4**  | $15.00                | $75.00                  | 200K tokens        |\n",
    "| **Claude Sonnet 4**| $3.00                 | $15.00                  | 200K tokens        |\n",
    "| **Claude Haiku 4** | $0.80                 | $4.00                   | 200K tokens        |\n",
    "\n",
    "*Note: Anthropic prices are per million (1M) tokens, while OpenAI typically shows per 1K tokens.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03196886-9670-4fde-9275-6913ba9929c9",
   "metadata": {},
   "source": [
    "## A widget to calculate costs of token consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd53752-bee4-4322-b70f-b0719675a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define token prices (per 1M tokens)\n",
    "token_prices = {\n",
    "    \"claude-opus-4\": {\"input\": 15.00, \"output\": 75.00},\n",
    "    \"claude-sonnet-4\": {\"input\": 3.00, \"output\": 15.00},\n",
    "    \"claude-haiku-4\": {\"input\": 0.80, \"output\": 4.00},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f6e5c-2b7c-4943-a6ef-8e84e5591548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widgets\n",
    "model_selector = widgets.Dropdown(\n",
    "    options=list(token_prices.keys()),\n",
    "    value=\"claude-sonnet-4\",\n",
    "    description='Model:',)\n",
    "\n",
    "input_tokens = widgets.IntText(\n",
    "    value=1000,\n",
    "    description='Input Tokens:',)\n",
    "\n",
    "output_tokens = widgets.IntText(\n",
    "    value=500,\n",
    "    description='Output Tokens:',)\n",
    "\n",
    "estimate_button = widgets.Button(\n",
    "    description=\"Estimate Cost\",\n",
    "    button_style=\"success\")\n",
    "\n",
    "cost_display = widgets.Label(value=\"\")\n",
    "\n",
    "# Define the estimator (note: prices are per 1M tokens for Anthropic)\n",
    "def estimate_cost(b):\n",
    "    model = model_selector.value\n",
    "    input_count = input_tokens.value\n",
    "    output_count = output_tokens.value\n",
    "    prices = token_prices[model]\n",
    "    cost = (input_count / 1_000_000) * prices[\"input\"] + (output_count / 1_000_000) * prices[\"output\"]\n",
    "    cost_display.value = f\"💲 Estimated Cost: ${cost:.6f}\"\n",
    "\n",
    "estimate_button.on_click(estimate_cost)\n",
    "\n",
    "# Display everything\n",
    "display(model_selector, input_tokens, output_tokens, estimate_button, cost_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56769326-5e7a-4d92-9edc-a35f65e4fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a message to Claude\n",
    "response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    system=\"You are a UC Berkeley Economics Student\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain who pays the burden of tariffs\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Display response\n",
    "print(response.content[0].text)\n",
    "\n",
    "# Display token usage\n",
    "print(\"\\n📢 Token Usage:\")\n",
    "print(f\"Input tokens: {response.usage.input_tokens}\")\n",
    "print(f\"Output tokens: {response.usage.output_tokens}\")\n",
    "print(f\"Total tokens: {response.usage.input_tokens + response.usage.output_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763fc99-1359-4ecb-af54-2c4aacad68f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a message with various parameters\n",
    "response = client.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=200,               # max length of the response\n",
    "    temperature=0.7,              # creativity level (0 = deterministic, 1 = max randomness)\n",
    "    top_p=1.0,                    # nucleus sampling\n",
    "    system=\"You are a UC Berkeley Economics Student\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Explain who pays the burden of tariffs\"}\n",
    "    ],\n",
    "    stop_sequences=None           # can be a list of strings to stop generation early\n",
    ")\n",
    "\n",
    "# Display the response text\n",
    "print(\"📘 Response:\")\n",
    "print(response.content[0].text)\n",
    "\n",
    "# Display token usage\n",
    "print(\"\\n📢 Token Usage:\")\n",
    "print(f\"Input tokens: {response.usage.input_tokens}\")\n",
    "print(f\"Output tokens: {response.usage.output_tokens}\")\n",
    "print(f\"Total tokens: {response.usage.input_tokens + response.usage.output_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8631f29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
